{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c34b4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf37f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739d2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train_data=pd.read_table(\"data/nsmc/ratings_train.txt\")\n",
    "nsmc_test_data=pd.read_table(\"data/nsmc/ratings_test.txt\")\n",
    "kaggle_data=pd.read_table(\"data/kaggle/kr3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d7f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#네이버 영화 평점 데이터 라벨 분포(0:부정, 1:긍정)\n",
    "nsmc_train_data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78f9a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#kaggle 레스토랑 평점 데이터 라벨 분포(0:부정,1:긍정,2:모호함)\n",
    "kaggle_data['Rating'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96b9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리, 중복과 null값 제거\n",
    "#train\n",
    "nsmc_train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "nsmc_train_data=nsmc_train_data.dropna(how='any')\n",
    "#test\n",
    "nsmc_test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "nsmc_test_data=nsmc_train_data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2c23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리, [CLS](문장 시작 토큰)와 [SEP](문장 종료 토큰)붙이기\n",
    "#train data\n",
    "document_train_data=[\"[CLS]\"+str(s)+\" [SEP]\" for s in nsmc_train_data.document]\n",
    "\n",
    "#test data\n",
    "sentences=nsmc_test_data['document']\n",
    "document_test_data=[\"[CLS]\"+str(s)+\" [SEP]\" for s in sentences]\n",
    "labels=nsmc_test_data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7c31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n",
      "['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#토크나이징\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "#train data\n",
    "tokenized_train_texts = [tokenizer.tokenize(s) for s in document_train_data]\n",
    "#test data\n",
    "tokenized_test_texts = [tokenizer.tokenize(s) for s in document_test_data]\n",
    "\n",
    "print(tokenized_train_texts[0])\n",
    "print(tokenized_test_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc4da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#패딩\n",
    "MAX_LEN = 128\n",
    "#train data\n",
    "input_train_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_train_texts]\n",
    "input_train_ids = pad_sequences(input_train_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n",
    "#test data\n",
    "input_test_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_test_texts]\n",
    "input_test_ids = pad_sequences(input_test_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n",
    "\n",
    "input_train_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ce759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#어텐션 마스크\n",
    "attention_train_masks = []\n",
    "attention_test_masks=[]\n",
    "\n",
    "for seq in input_train_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_train_masks.append(seq_mask)\n",
    "    \n",
    "for seq in input_test_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_test_masks.append(seq_mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train용 학습 데이터 전처리\n",
    "#train - validation set 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels =\\\n",
    "train_test_split(input_train_ids, nsmc_train_data['label'].values, random_state=42, test_size=0.1)#input과 mask를 섞이지 않게 random_state seed를 고정\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_train_masks, \n",
    "                                                       input_train_ids,\n",
    "                                                       random_state=42, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "#train dataset sampling\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "#test dataset sampling\n",
    "test_inputs = torch.tensor(input_test_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_test_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143c19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch & dataloader setting\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "#train\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "#validation\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n",
    "#test\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af7b00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 설정(BERT)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494618d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DESKTOP\\anaconda3\\envs\\a2\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#옵티마이저 설정(AdamW)\n",
    "optimizer=AdamW(model.parameters(),\n",
    "               lr=2e-5,\n",
    "               eps=1e-8\n",
    "               )\n",
    "\n",
    "epochs=4\n",
    "\n",
    "total_steps=len(train_dataloader)*epochs\n",
    "\n",
    "scheduler=get_linear_schedule_with_warmup(optimizer,\n",
    "                                         num_warmup_steps=0,\n",
    "                                         num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c3c060",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 정확도 계산\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# 시간 표시\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 train 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device).long() for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device).long() for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf2627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
